import { BinaryReader, BinaryWriter } from "./binary.js";
import { BorshError } from "./error.js";
import { FixedArrayKind, OptionKind, StringType, StructKind, VecKind, extendingClasses, getOffset, } from "./types.js";
export * from "./binary.js";
export * from "./types.js";
export * from "./error.js";
/**
 * Code below is quite optimized for performance hence there will be some "wierd" looking .js
 * Overall, they way it works, is that each Schema is translated into one big callback function that can execute very efficiently multiple time
 * This function or handle, is stored on the prototypes so we can easily access it when we want to serialize/deserialize
 */
// we will store some metadata about the schemas on the prototype. Prototype set get is faster if we use numbers (so we are going to use that here)
const MAX_PROTOTYPE_SEARCH = 250;
const PROTOTYPE_POLLUTION_CONTEXT_RANGE = 500;
const PROTOTYPE_DESERIALIZATION_HANDLER_OFFSET = 500;
const PROTOTYPE_DEPENDENCY_HANDLER_OFFSET = PROTOTYPE_DESERIALIZATION_HANDLER_OFFSET + PROTOTYPE_POLLUTION_CONTEXT_RANGE;
const PROTOTYPE_SCHEMA_OFFSET = PROTOTYPE_DESERIALIZATION_HANDLER_OFFSET +
    PROTOTYPE_POLLUTION_CONTEXT_RANGE * 2;
/**
 * Serialize an object with @field(...) or @variant(...) decorators
 * @param obj
 * @returns bytes
 */
export function serialize(obj, writer = new BinaryWriter()) {
    (obj.constructor._borsh_serialize ||
        (obj.constructor._borsh_serialize = serializeStruct(obj.constructor, true)))(obj, writer);
    return writer.finalize();
}
function recursiveSerialize(obj, writer = new BinaryWriter()) {
    (obj.constructor._borsh_serialize_recursive ||
        (obj.constructor._borsh_serialize_recursive = serializeStruct(obj.constructor, false)))(obj, writer);
    return writer.finalize();
}
export function deserialize(buffer, classType, options) {
    // buffer = intoUint8Array(buffer);
    const reader = new BinaryReader(buffer);
    let fromBuffer = buffer.constructor !== Uint8Array;
    const result = deserializeStruct(classType, fromBuffer)(reader, options);
    if (!options?.unchecked && reader._offset !== buffer.length) {
        throw new BorshError(`Unexpected ${buffer.length - reader._offset} bytes after deserialized data. This is most likely due to that you are deserializing into the wrong class`);
    }
    return result;
}
function serializeField(fieldName, fieldType, options) {
    if (typeof fieldType.serialize == "function") {
        return (obj, writer) => fieldType.serialize(obj, writer);
    }
    try {
        const handleFn = () => {
            if (typeof fieldType === "string") {
                return BinaryWriter.write(fieldType);
            }
            else if (fieldType === Uint8Array) {
                return BinaryWriter.uint8Array;
            }
            else if (fieldType instanceof OptionKind) {
                const fieldHandle = serializeField(fieldName, fieldType.elementType);
                return (obj, writer) => {
                    if (obj != null) {
                        writer.u8(1);
                        fieldHandle(obj, writer);
                    }
                    else {
                        writer.u8(0);
                    }
                };
            }
            else if (fieldType instanceof VecKind ||
                fieldType instanceof FixedArrayKind) {
                if (fieldType.elementType === "u8") {
                    if (fieldType instanceof FixedArrayKind) {
                        return options?.unchecked
                            ? BinaryWriter.uint8ArrayFixed
                            : (obj, writer) => {
                                if (obj.length !== fieldType.length) {
                                    throw new BorshError(`Provided array does not equal fixed array size of field: ${fieldName}. Recieved: ${obj.length}, Expected: ${fieldType.length}`);
                                }
                                return BinaryWriter.uint8ArrayFixed(obj, writer);
                            };
                    }
                    else {
                        if (fieldType.sizeEncoding === "u32")
                            return BinaryWriter.uint8Array;
                        else {
                            const [sizeHandle, width] = BinaryWriter.smallNumberEncoding(fieldType.sizeEncoding);
                            return (obj, writer) => BinaryWriter.uint8ArrayCustom(obj, writer, sizeHandle, width);
                        }
                    }
                }
                else {
                    const sizeHandle = fieldType instanceof FixedArrayKind
                        ? undefined
                        : BinaryWriter.write(fieldType.sizeEncoding);
                    const fieldHandle = serializeField(null, fieldType.elementType);
                    return (obj, writer) => {
                        let len = obj.length;
                        if (!sizeHandle) {
                            if (fieldType.length != len) {
                                throw new BorshError(`Expecting array of length ${fieldType[0]}, but got ${obj.length}`);
                            }
                        }
                        else {
                            sizeHandle(len, writer); // For dynamically sized array we write the size as uX according to specification
                        }
                        for (let i = 0; i < len; i++) {
                            fieldHandle(obj[i], writer);
                        }
                    };
                }
            }
            else if (fieldType instanceof StringType) {
                const [sizeHandle, width] = BinaryWriter.smallNumberEncoding(fieldType.sizeEncoding);
                return (obj, writer) => BinaryWriter.stringCustom(obj, writer, sizeHandle, width);
            }
            else {
                return (obj, writer) => {
                    if (!options?.unchecked &&
                        !checkClazzesCompatible(obj.constructor, fieldType)) {
                        throw new BorshError(`Field value of field ${fieldName} is not instance of expected Class ${getSuperMostClass(fieldType)?.name}. Got: ${obj.constructor.name}`);
                    }
                    serializeStruct(obj.constructor)(obj, writer);
                };
            }
        };
        const handle = handleFn();
        if (!options?.unchecked) {
            return (obj, writer) => {
                if (obj == null && fieldType instanceof OptionKind === false) {
                    throw new BorshError(`Trying to serialize a null value to field "${fieldName}" which is not allowed since the field is not decorated with "option(...)" but "${typeof fieldType === "function" && fieldType?.name ? fieldType?.name : fieldType}". Most likely you have forgotten to assign this value before serializing`);
                }
                return handle(obj, writer);
            };
        }
        else {
            return handle;
        }
    }
    catch (error) {
        if (error instanceof BorshError) {
            error.addToFieldPath(fieldName);
        }
        throw error;
    }
}
function serializeStruct(ctor, allowCustomSerializer = true) {
    let handle = undefined;
    var i = 0;
    let once = false;
    while (true) {
        let schema = getSchema(ctor, i);
        if (schema) {
            once = true;
            const index = schema.variant;
            if (index != undefined) {
                let prev = handle;
                if (typeof index === "number") {
                    handle = prev
                        ? (obj, writer) => {
                            prev(obj, writer);
                            writer.u8(index);
                        }
                        : (_obj, writer) => BinaryWriter.u8(index, writer);
                }
                else if (Array.isArray(index)) {
                    if (prev) {
                        handle = (obj, writer) => {
                            prev(obj, writer);
                            for (const i of index) {
                                writer.u8(i);
                            }
                        };
                    }
                    else {
                        handle = (_obj, writer) => {
                            for (const i of index) {
                                writer.u8(i);
                            }
                        };
                    }
                }
                else {
                    // is string
                    handle = prev
                        ? (obj, writer) => {
                            prev(obj, writer);
                            writer.string(index);
                        }
                        : (_obj, writer) => writer.string(index);
                }
            }
            if (allowCustomSerializer && schema.serializer) {
                let prev = handle;
                handle = prev
                    ? (obj, writer) => {
                        prev(obj, writer);
                        schema.serializer(obj, writer, (obj) => recursiveSerialize(obj));
                    }
                    : (obj, writer) => schema.serializer(obj, writer, (obj) => recursiveSerialize(obj));
            }
            else {
                for (const field of schema.fields) {
                    let prev = handle;
                    const fieldHandle = serializeField(field.key, field.type);
                    if (prev) {
                        handle = (obj, writer) => {
                            prev(obj, writer);
                            fieldHandle(obj[field.key], writer);
                        };
                    }
                    else {
                        handle = (obj, writer) => fieldHandle(obj[field.key], writer);
                    }
                }
            }
        }
        else if (once && !getDependencies(ctor, i)?.length) {
            return handle;
        }
        i++;
        if (i == MAX_PROTOTYPE_SEARCH && !once) {
            throw new BorshError(`Class ${ctor.name} is missing in schema`);
        }
    }
}
const MAX_ARRAY_SIZE_ALLOCATION = 1024 * 1024;
function deserializeField(fieldName, fieldType, fromBuffer) {
    try {
        if (typeof fieldType === "string") {
            return BinaryReader.read(fieldType, fromBuffer);
        }
        if (fieldType === Uint8Array) {
            return (reader) => reader.uint8Array();
        }
        if (fieldType instanceof VecKind || fieldType instanceof FixedArrayKind) {
            if (fieldType.elementType === "u8") {
                if (fieldType instanceof FixedArrayKind) {
                    return (reader) => reader.buffer(fieldType.length);
                }
                else {
                    const sizeHandle = BinaryReader.read(fieldType.sizeEncoding, fromBuffer);
                    return (reader) => BinaryReader.uint8Array(reader, sizeHandle(reader));
                }
            }
            else {
                let sizeHandle = fieldType instanceof VecKind
                    ? BinaryReader.read(fieldType.sizeEncoding, fromBuffer)
                    : () => fieldType.length;
                const fieldHandle = deserializeField(null, fieldType.elementType, fromBuffer);
                return (reader, options) => {
                    const len = sizeHandle(reader);
                    if (len < MAX_ARRAY_SIZE_ALLOCATION) {
                        let arr = new Array(len);
                        for (let i = 0; i < len; i++) {
                            arr[i] = fieldHandle(reader, options);
                        }
                        return arr;
                    }
                    else {
                        let arr = new Array(MAX_ARRAY_SIZE_ALLOCATION);
                        for (let i = 0; i < len; i++) {
                            arr[i] = fieldHandle(reader, options);
                        }
                        return arr;
                    }
                };
            }
        }
        if (fieldType instanceof StringType) {
            const sizeReader = BinaryReader.read(fieldType.sizeEncoding, fromBuffer);
            return fromBuffer
                ? (reader) => BinaryReader.bufferStringCustom(reader, sizeReader)
                : (reader) => BinaryReader.stringCustom(reader, sizeReader);
        }
        if (typeof fieldType["deserialize"] == "function") {
            return (reader) => fieldType.deserialize(reader);
        }
        if (fieldType instanceof OptionKind) {
            const fieldHandle = deserializeField(fieldName, fieldType.elementType, fromBuffer);
            return (reader, options) => {
                return reader.bool() ? fieldHandle(reader, options) : undefined;
            };
        }
        return deserializeStruct(fieldType, fromBuffer);
    }
    catch (error) {
        if (error instanceof BorshError) {
            error.addToFieldPath(fieldName);
        }
        throw error;
    }
}
export function deserializeStruct(targetClazz, fromBuffer) {
    const handle = getCreateDeserializationHandle(targetClazz, 0, fromBuffer);
    // "compile time"
    return (reader, options) => {
        // "runtime"
        const result = handle({}, reader, options);
        if (!options?.unchecked &&
            !options?.object &&
            !checkClazzesCompatible(result.constructor, targetClazz)) {
            throw new BorshError(`Deserialization of ${targetClazz?.name || targetClazz} yielded another Class: ${result.constructor?.name} which are not compatible`);
        }
        return result;
    };
}
const getCreateDeserializationHandle = (clazz, offset, fromBuffer) => getDeserializationHandle(clazz, offset, fromBuffer) ||
    setDeserializationHandle(clazz, offset, fromBuffer, createDeserializeStructHandle(clazz, offset, fromBuffer));
const getDeserializationHandle = (clazz, offset, fromBuffer) => clazz.prototype[PROTOTYPE_DESERIALIZATION_HANDLER_OFFSET +
    offset +
    (fromBuffer ? MAX_PROTOTYPE_SEARCH : 0)];
const setDeserializationHandle = (clazz, offset, fromBuffer, handle) => (clazz.prototype[PROTOTYPE_DESERIALIZATION_HANDLER_OFFSET +
    offset +
    (fromBuffer ? MAX_PROTOTYPE_SEARCH : 0)] = handle);
const clearDeserializeStructHandle = (clazz, offset, fromBuffer) => delete clazz.prototype[PROTOTYPE_DESERIALIZATION_HANDLER_OFFSET +
    offset +
    (fromBuffer ? MAX_PROTOTYPE_SEARCH : 0)];
const createDeserializeStructHandle = (currClazz, offset, fromBuffer) => {
    let handle = undefined;
    let endHandle = (result, reader, options) => {
        if (options?.object) {
            return result;
        }
        return Object.assign(options?.construct
            ? new currClazz()
            : Object.create(currClazz.prototype), result);
    };
    let structSchema = getSchema(currClazz, offset);
    if (structSchema) {
        if (offset === 0) {
            let index = getVariantIndex(structSchema);
            if (index != null) {
                // It is an (stupid) enum, but we deserialize into its variant directly
                // This means we should omit the variant index
                if (typeof index === "number") {
                    handle = (_, reader, __) => {
                        reader._offset += 1; // read 1 u
                    };
                }
                else if (Array.isArray(index)) {
                    handle = (_, reader, __) => {
                        reader._offset += index.length; // read all u8's 1 u8 = 1 byte -> shift offset with 1*length
                    };
                }
                else {
                    // string
                    handle = (_, reader, __) => {
                        reader.string();
                    };
                }
            }
        }
        for (const field of structSchema.fields) {
            const prev = handle;
            const fieldHandle = deserializeField(field.key, field.type, fromBuffer);
            if (prev) {
                handle = (result, reader, options) => {
                    prev(result, reader, options);
                    result[field.key] = fieldHandle(reader, options);
                };
            }
            else
                handle = (result, reader, options) => {
                    result[field.key] = fieldHandle(reader, options);
                };
        }
    }
    // We know that we should serialize into the variant that accounts to the first byte of the read
    let dependencies = getAllDependencies(currClazz, offset);
    if (dependencies) {
        let variantToDepndency = [];
        let variantType;
        for (const [actualClazz, dependency] of dependencies) {
            const variantIndex = getVariantIndex(dependency.schema);
            let currentVariantType = typeof variantIndex === "object"
                ? variantIndex.length
                : typeof variantIndex;
            if (!variantType) {
                variantType = currentVariantType;
            }
            else if (currentVariantType !== variantType) {
                throw new Error(`Variant extending ${currClazz.name} have different types, expecting either number, number[] (with same sizes) or string, but not a combination of them`);
            }
            variantToDepndency.push([variantIndex, actualClazz, dependency]);
        }
        if (variantType === "undefined") {
            if (dependencies.size === 1) {
                const dep = variantToDepndency[0];
                return (result, reader, options) => {
                    handle && handle(result, reader, options);
                    return getCreateDeserializationHandle(dep[1], dep[2].offset, fromBuffer)(result, reader, options);
                };
            }
            else
                throw new BorshError(`Failed to find class to deserialize to from ${currClazz.name}: but no variants are used which makes deserialization undeterministic`);
        }
        return (result, reader, options) => {
            handle && handle(result, reader, options);
            let next = undefined;
            let nextOffset = undefined;
            if (variantType === "number") {
                let agg = reader.u8();
                for (const dep of variantToDepndency) {
                    if (agg === dep[0]) {
                        return getCreateDeserializationHandle(dep[1], dep[2].offset, fromBuffer)(result, reader, options);
                    }
                }
            }
            else if (variantType === "string") {
                let variant = reader.string();
                for (const dep of variantToDepndency) {
                    if (variant === dep[0]) {
                        return getCreateDeserializationHandle(dep[1], dep[2].offset, fromBuffer)(result, reader, options);
                    }
                }
            } // array
            else {
                let agg = [];
                for (let i = 0; i < variantType; i++) {
                    agg.push(reader.u8());
                }
                for (const dep of variantToDepndency) {
                    let currentVariant = dep[0];
                    if (currentVariant.length === agg.length &&
                        currentVariant.every((value, index) => value === agg[index])) {
                        return getCreateDeserializationHandle(dep[1], dep[2].offset, fromBuffer)(result, reader, options);
                    }
                }
            }
            if (next == undefined && dependencies) {
                // do a recursive call and copy result,
                // this is not computationally performant since we are going to traverse multiple path
                // and possible do deserialziation on bad paths
                if (dependencies.size == 1) {
                    // still deterministic
                    const n = dependencies.entries().next().value;
                    next = n[0];
                    nextOffset = n[1].offset;
                }
                else if (dependencies.size > 1) {
                    const classes = [...dependencies.entries()]
                        .map(([c]) => c.name)
                        .join(", ");
                    throw new BorshError(`Failed to find class to deserialize to from ${currClazz.name} found: ${classes} but no variant matches bytes read from the buffer.`);
                }
            }
            if (next != null) {
                getCreateDeserializationHandle(next, nextOffset, fromBuffer)(result, reader, options);
            }
            else {
                return endHandle(result, reader, options);
            }
        };
    }
    else {
        if (handle) {
            return (result, reader, options) => {
                handle(result, reader, options);
                return endHandle(result, reader, options);
            };
        }
        return endHandle;
    }
};
const getOrCreateStructMeta = (clazz, offset) => {
    let schema = getSchema(clazz, offset);
    if (!schema) {
        schema = new StructKind();
    }
    setSchema(clazz, schema, offset);
    return schema;
};
const setDependencyToProtoType = (ctor, offset) => {
    let proto = Object.getPrototypeOf(ctor);
    while (proto.prototype?.constructor != undefined) {
        // TODO break early if already done this!
        let newOffset = --offset;
        let dependencies = getDependencies(proto, newOffset);
        if (dependencies) {
            for (const dependency of dependencies) {
                if (ctor.prototype instanceof dependency || dependency === ctor) {
                    return;
                }
            }
        }
        else {
            dependencies = [];
        }
        dependencies.push(ctor);
        setDependencies(proto, newOffset, dependencies);
        proto = Object.getPrototypeOf(proto);
    }
};
const getSuperMostClass = (clazz) => {
    while (Object.getPrototypeOf(clazz).prototype != undefined) {
        clazz = Object.getPrototypeOf(clazz);
    }
    return clazz;
};
/**
 * @param clazzA
 * @param clazzB
 * @returns true if A inherit B or B inherit A or A == B, else false
 */
const checkClazzesCompatible = (clazzA, clazzB) => {
    return (clazzA == clazzB ||
        clazzA.isPrototypeOf(clazzB) ||
        clazzB.isPrototypeOf(clazzA));
};
export const getDependencies = (ctor, offset) => ctor.prototype[PROTOTYPE_DEPENDENCY_HANDLER_OFFSET + offset];
const setDependencies = (ctor, offset, dependencies) => {
    ctor.prototype[PROTOTYPE_DEPENDENCY_HANDLER_OFFSET + offset] = dependencies; // [getDependencyKey(ctor)]
};
export const getAllDependencies = (ctor, offset) => {
    let existing = getDependencies(ctor, offset);
    if (existing) {
        let ret = new Map();
        for (const v of existing) {
            let schema = getSubMostSchema(v);
            if (schema.fields.length > 0 || schema.variant != undefined) {
                // non trivial
                ret.set(v, { schema, offset: getOffset(v) });
            }
            else {
                // check recursively
                let req = getAllDependencies(v, offset);
                for (const [rv, rk] of req) {
                    ret.set(rv, rk);
                }
            }
        }
        return ret;
    }
};
const getDependenciesRecursively = (ctor, offset, mem = []) => {
    let dep = getDependencies(ctor, offset);
    if (dep) {
        for (const f of dep) {
            if (mem.includes(f)) {
                continue;
            }
            mem.push(f);
            getDependenciesRecursively(f, offset, mem);
        }
    }
    return mem;
};
const setSchema = (ctor, schemas, offset) => {
    ctor.prototype[PROTOTYPE_SCHEMA_OFFSET + offset] = schemas;
};
export const getSchema = (ctor, offset = getOffset(ctor)) => ctor.prototype[PROTOTYPE_SCHEMA_OFFSET + offset];
const getSubMostSchema = (ctor) => {
    let last = undefined;
    for (var i = 0; i < MAX_PROTOTYPE_SEARCH; i++) {
        const curr = ctor.prototype[PROTOTYPE_SCHEMA_OFFSET + i];
        if (!curr && last && !getDependencies(ctor, i)?.length) {
            return last;
        }
        last = curr;
    }
    return;
};
export const getSchemasBottomUp = (ctor) => {
    let last = undefined;
    let ret = [];
    for (var i = 0; i < 1000; i++) {
        const curr = getSchema(ctor, i);
        if (!curr) {
            if (last && !getDependencies(ctor, i)?.length) {
                return ret;
            }
        }
        else {
            ret.push(curr);
            last = curr;
        }
    }
    return ret;
};
/**
 *
 * @param kind 'struct' or 'variant. 'variant' equivalnt to Rust Enum
 * @returns Schema decorator function for classes
 */
export const variant = (index) => {
    return (ctor) => {
        let offset = getOffset(ctor);
        setDependencyToProtoType(ctor, offset);
        let schemas = getOrCreateStructMeta(ctor, offset);
        schemas.variant = index;
        // clear deserialization handles for all dependencies since we might have made a dynamic import which breakes the deserialization path caches
        for (const clazz of extendingClasses(ctor)) {
            clearDeserializeStructHandle(clazz, 0, true);
            clearDeserializeStructHandle(clazz, 0, false);
        }
        // Check for variant conficts
        for (let i = offset - 1; i >= 0; i--) {
            const dependencies = getDependencies(ctor, i);
            if (dependencies) {
                for (const dependency of dependencies) {
                    if (dependency !== ctor) {
                        let otherVariant = getVariantIndex(getSchema(dependency, getOffset(dependency)));
                        if (typeof otherVariant !== typeof index) {
                            throw new BorshError(`Variant of ${ctor.name} have different type compared to its sibling: ${dependency.name}, expecting either number, number[] (with same sizes) or string, but not a combination of them`);
                        }
                        else if (index === otherVariant ||
                            (Array.isArray(index) &&
                                Array.isArray(otherVariant) &&
                                (index.length !== otherVariant.length ||
                                    index.every((value, index) => value === otherVariant[index])))) {
                            throw new BorshError(`Variant of ${ctor.name}: ${JSON.stringify(index)} is the same as for ${dependency.name} which is not allowed (non-determinism)`);
                        }
                    }
                    if (getVariantIndex(getSchema(dependency, getOffset(dependency))) !=
                        null) {
                        return; // No need to validate more
                    }
                }
            }
            if (getVariantIndex(getSchema(ctor, i)) != null) {
                return; // No need to validate more
            }
        }
    };
};
const getVariantIndex = (schema) => {
    return schema.variant;
};
/**
 * @param properties, the properties of the field mapping to schema
 * @returns
 */
export function field(properties) {
    return (target, name) => {
        const offset = getOffset(target.constructor);
        setDependencyToProtoType(target.constructor, offset);
        const schemas = getOrCreateStructMeta(target.constructor, offset);
        const schema = schemas;
        const key = name.toString();
        let field = undefined;
        if (properties["type"] != undefined) {
            field = {
                key,
                type: properties["type"],
            };
        }
        else {
            field = {
                key,
                type: properties,
            };
        }
        if (properties.index === undefined) {
            schema.fields.push(field); // add to the end. This will make property decorator execution order define field order
        }
        else {
            if (schema.fields[properties.index]) {
                throw new BorshError("Multiple fields defined at the same index: " +
                    properties.index +
                    ", class: " +
                    target.constructor.name);
            }
            if (properties.index >= schema.fields.length) {
                resize(schema.fields, properties.index + 1, undefined);
            }
            schema.fields[properties.index] = field;
        }
    };
}
/**
 * @experimental
 * @param properties, the properties of the field mapping to schema
 * @returns
 */
export function serializer() {
    return function (target, propertyKey) {
        const offset = getOffset(target.constructor);
        const schemas = getOrCreateStructMeta(target.constructor, offset);
        schemas.serializer = (obj, writer, serialize) => obj[propertyKey](writer, serialize);
    };
}
/**
 * @param clazzes
 * @param validate, run validation?
 * @returns Schema map
 */
export const validate = (clazzes, allowUndefined = false) => {
    return validateIterator(clazzes, allowUndefined, new Set());
};
const validateIterator = (clazzes, allowUndefined, visited) => {
    clazzes = Array.isArray(clazzes) ? clazzes : [clazzes];
    let schemas = new Map();
    clazzes.forEach((clazz, ix) => {
        clazz = getSuperMostClass(clazz);
        let dependencies = getDependenciesRecursively(clazz, getOffset(clazz));
        dependencies.push(clazz);
        dependencies.forEach((v, k) => {
            const schema = getSchema(v);
            if (!schema) {
                return;
            }
            schemas.set(v, schema);
            visited.add(v.name);
        });
        let lastVariant = undefined;
        let lastKey = undefined;
        getAllDependencies(clazz, getOffset(clazz))?.forEach((dependency, key) => {
            if (!lastVariant)
                lastVariant = getVariantIndex(dependency.schema);
            else if (!validateVariantAreCompatible(lastVariant, getVariantIndex(dependency.schema))) {
                throw new BorshError(`Class ${key.name} is extended by classes with variants of different types. Expecting only one of number, number[] or string`);
            }
            if (lastKey != undefined && lastVariant == undefined) {
                throw new BorshError(`Classes inherit ${clazz} and are introducing new field without introducing variants. This leads to unoptimized deserialization`);
            }
            lastKey = key;
        });
        schemas.forEach((structSchema, clazz) => {
            structSchema.fields.forEach((field) => {
                if (!field) {
                    throw new BorshError("Field is missing definition, most likely due to field indexing with missing indices");
                }
                if (allowUndefined) {
                    return;
                }
                if (field.type instanceof Function) {
                    // Treat Uint8Array as a known built-in type
                    if (field.type === Uint8Array) {
                        return;
                    }
                    if (!getSchema(field.type) &&
                        !getAllDependencies(field.type, getOffset(clazz))?.size) {
                        throw new BorshError("Unknown field type: " + field.type.name);
                    }
                    // Validate field
                    validateIterator(field.type, allowUndefined, visited);
                }
            });
        });
    });
};
const resize = (arr, newSize, defaultValue) => {
    while (newSize > arr.length)
        arr.push(defaultValue);
    arr.length = newSize;
};
const validateVariantAreCompatible = (a, b) => {
    if (typeof a != typeof b) {
        return false;
    }
    if (Array.isArray(a) && Array.isArray(b)) {
        if (a.length != b.length) {
            return false;
        }
    }
    return true;
};
export const getDiscriminator = (constructor) => {
    const schemas = getSchemasBottomUp(constructor);
    const writer = new BinaryWriter();
    for (let i = 0; i < schemas.length; i++) {
        const clazz = schemas[i];
        if (i !== schemas.length - 1 && clazz.fields.length > 0) {
            throw new BorshError("Discriminator can not be resolved for inheritance where super class contains fields, undefined behaviour");
        }
        const variant = clazz.variant;
        if (variant == undefined) {
            continue;
        }
        if (typeof variant === "string") {
            writer.string(variant);
        }
        else if (typeof variant === "number") {
            writer.u8(variant);
        }
        else if (Array.isArray(variant)) {
            variant.forEach((v) => {
                writer.u8(v);
            });
        }
        else {
            throw new BorshError("Can not resolve discriminator for variant with type: " +
                typeof variant);
        }
    }
    return writer.finalize();
};
//# sourceMappingURL=index.js.map